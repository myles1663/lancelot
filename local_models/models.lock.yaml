# ==========================================================
# Local Utility Model Lockfile (v8 Upgrade — Qwen3-8B)
# ==========================================================
# Pinned model metadata — weights are NOT bundled.
# Downloaded from upstream with user consent during onboarding.
#
# Spec reference: §3.1 What Is Included
# ==========================================================

model:
  name: "qwen3-8b"
  version: "3.0"
  quantization: "Q4_K_M"
  format: "gguf"
  filename: "Qwen3-8B-Q4_K_M.gguf"
  size_mb: 5000

  # SHA-256 checksum for integrity verification
  checksum:
    algorithm: "sha256"
    hash: "0000000000000000000000000000000000000000000000000000000000000000"

  # Download sources (tried in order)
  sources:
    - url: "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q4_K_M.gguf"
      provider: "huggingface"

  # Licensing
  license:
    model: "Apache-2.0"
    runtime: "MIT"

# Runtime configuration
runtime:
  engine: "llama.cpp"
  context_length: 8192
  threads: 4
  gpu_layers: 28  # Partial GPU offload (GTX 1070 8GB, ~4GB free VRAM)

# Prompt suite references
prompts:
  - classify_intent
  - extract_json
  - summarize_internal
  - redact
  - rag_rewrite
