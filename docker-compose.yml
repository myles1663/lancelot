services:
  lancelot-core:
    build: .
    container_name: lancelot_core
    volumes:
      - ./lancelot_data:/home/lancelot/data
      # Map the current directory to /home/lancelot/app for development
      - .:/home/lancelot/app
      # Docker socket for sandbox provider (sibling containers)
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount Google OAuth credentials (ADC) from host (uncomment if using Google OAuth)
      # - ${APPDATA}/gcloud/application_default_credentials.json:/home/lancelot/.config/gcloud/application_default_credentials.json:ro
    group_add:
      - "0"  # root group to access Docker socket (owned root:root on Docker Desktop)
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      # - GOOGLE_APPLICATION_CREDENTIALS=/home/lancelot/.config/gcloud/application_default_credentials.json
      - LOCAL_LLM_URL=http://local-llm:8080
      - PYTHONPATH=/home/lancelot/app/src/core:/home/lancelot/app/src/ui:/home/lancelot/app/src/agents:/home/lancelot/app/src/memory:/home/lancelot/app/src/shared:/home/lancelot/app/src/integrations:/home/lancelot/app/src:/home/lancelot/app
    depends_on:
      local-llm:
        condition: service_healthy
    ports:
      - "8000:8000"
      - "8501:8501"
    command: sh -c "uvicorn gateway:app --host 0.0.0.0 --port 8000 & streamlit run src/ui/war_room.py --server.port 8501 --server.address 0.0.0.0"
    networks:
      - lancelot_net

  local-llm:
    build:
      context: ./local_models
      dockerfile: Dockerfile
    container_name: lancelot_local_llm
    volumes:
      # Model weights â€” downloaded during onboarding, never baked into image
      - ./local_models/weights:/home/llm/models:ro
    environment:
      - LOCAL_MODELS_DIR=/home/llm/models
      - LOCAL_MODEL_CTX=8192
      - LOCAL_MODEL_THREADS=4
      - LOCAL_MODEL_GPU_LAYERS=28
      - LOCAL_LLM_PORT=8080
    # Fix Pack V8: GPU access for CUDA offload
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s
      retries: 3
    restart: unless-stopped
    networks:
      - lancelot_net

networks:
  lancelot_net:
    driver: bridge
